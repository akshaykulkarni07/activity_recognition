{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from torch.autograd import Variable\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('data_preparation/train.csv', header = 0, index_col = 0)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('data_preparation/test.csv', header = 0, index_col = 0)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('data_preparation/val.csv', header = 0, index_col = 0)\n",
    "        self.transform = transform\n",
    "        self.df = self.df.reset_index()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df.iloc[idx : idx + 80, 3 : ].values\n",
    "        ind = np.argmax(np.sum(y, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + 80, : 3].values\n",
    "        x = x.astype('float')\n",
    "        assert(x.shape == (80, 3))\n",
    "        assert(label.shape == (6, ))\n",
    "        return x, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 10240\n",
    "batch_size = 256\n",
    "def my_collate(batch):\n",
    "    \"Puts each data field into a tensor with outer dimension batch size\"\n",
    "    batch = list(filter(lambda x : x is not None, batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "# train_indices = [(i * 80) for i in range(len(trainset) // 80)]\n",
    "# val_indices = [(i * 80) for i in range(len(valset) // 80)]\n",
    "# test_indices = [(i * 80) for i in range(len(testset) // 80)]\n",
    "\n",
    "# trainloader = DataLoader(trainset, batch_size = batch_size, sampler = SubsetRandomSampler(train_indices), collate_fn = my_collate, drop_last = True)\n",
    "# valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), collate_fn = my_collate, drop_last = True)\n",
    "# testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), collate_fn = my_collate, drop_last = True)\n",
    "\n",
    "train_indices = [i for i in range(len(trainset) - 80)]\n",
    "val_indices = [i for i in range(len(valset) - 80)]\n",
    "test_indices = [i for i in range(len(testset) - 80)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), collate_fn = my_collate, drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), collate_fn = my_collate, drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), collate_fn = my_collate, drop_last = True)\n",
    "\n",
    "# for idx, (x, y) in enumerate(trainloader) :\n",
    "#     print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on GPU\n"
     ]
    }
   ],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self, code_size):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        self.code_size = code_size\n",
    "        # defining layers\n",
    "        # input size - batch_size x 3 x 100\n",
    "        conv1 = nn.Conv1d(3, 10, 3)\n",
    "        # after conv1 - batch_size x 10 x 98\n",
    "        conv2 = nn.Conv1d(10, 20, 1)\n",
    "        # after conv2 - batch_size x 10 x 98\n",
    "        enc_fc = nn.Linear(10 * 98, self.code_size)\n",
    "        dec_fc = nn.Linear(self.code_size, 10 * 98)\n",
    "        deconv2 = nn.ConvTranspose1d(20, 10, 1)\n",
    "        deconv1 = nn.ConvTranspose1d(10, 3, 3)\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        code = self.encode(signal)\n",
    "        out = self.decode(code)\n",
    "        return out, code\n",
    "    \n",
    "    def encode(signal):\n",
    "        signal = signal.view(16, 3, 80)\n",
    "        code = F.sigmoid(self.conv1(signal))\n",
    "        code = F.sigmoid(self.conv2(code))\n",
    "        code = F.sigmoid(self.enc_fc(code))\n",
    "        return code\n",
    "    \n",
    "    def decode(code):\n",
    "        out = F.sigmoid(self.dec_fc(code))\n",
    "        out = F.sigmoid(self.deconv2(out))\n",
    "        out = F.sigmoid(self.deconv1(out))\n",
    "        return out\n",
    "    \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 10, 5)\n",
    "        self.conv3 = nn.Conv1d(10, 10, 5)\n",
    "        self.conv4 = nn.Conv1d(10, 10, 3)\n",
    "        self.conv5 = nn.Conv1d(10, 10, 3)\n",
    "        self.fc = nn.Linear(66 * 10, 6)\n",
    "#         self.dropout = nn.Dropout(0.25)\n",
    "#         self.bn = nn.BatchNorm1d(5)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv4.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv5.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal = signal.view(-1, 3, 80)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "#         out = self.dropout(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "#         out = self.dropout(out)\n",
    "        out = F.relu(self.conv3(out))\n",
    "#         out = self.dropout(out)\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.relu(self.conv5(out))\n",
    "        out = out.view(-1, 66 * 10)\n",
    "        out = self.fc(out)\n",
    "#         out = self.dropout(out)\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "    \n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()\n",
    "\n",
    "Net.load_state_dict(torch.load('model_5convlayer_lr1e-3.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.0\n",
      "74.0\n",
      "70.0\n",
      "68.0\n"
     ]
    }
   ],
   "source": [
    "def output_size(n, f, p = 0, s = 1):\n",
    "    return (((n + 2 * p - f) / s) + 1)\n",
    "\n",
    "print(output_size(80, 3))\n",
    "print(output_size(78, 5))\n",
    "print(output_size(74, 5))\n",
    "print(output_size(70, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // train_batch_size\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        images = Variable(images).cuda().float()\n",
    "        labels = Variable(labels).cuda()\n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "#         clear_output(wait=True)\n",
    "#         print(f'epoch: {epoch}, step : {i * len(images)} of {total_step}, loss : {loss}')\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "\n",
    "#             loss = criterion(outputs.float(), labels.float())\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "#     print(f'validation loss : {sum(val)/len(val)}')\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), 'model_dropout.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('conv1.weight', tensor([[[-0.2538,  0.4009, -0.4006],\n",
      "         [ 0.2252, -0.1528, -0.6841],\n",
      "         [-0.2669, -0.1826,  0.4054]],\n",
      "\n",
      "        [[ 0.6621, -0.4298, -0.4978],\n",
      "         [-0.2886, -0.3838,  0.0866],\n",
      "         [ 0.5184,  0.6247, -0.6648]],\n",
      "\n",
      "        [[ 0.5460,  0.6890, -0.0698],\n",
      "         [ 0.1503, -0.0947, -0.2529],\n",
      "         [-0.1997,  0.2127,  0.0085]],\n",
      "\n",
      "        [[-0.3807,  0.0490,  0.1034],\n",
      "         [ 0.1895, -0.6926, -0.1681],\n",
      "         [ 0.3082,  0.5064,  0.2634]],\n",
      "\n",
      "        [[ 0.0828, -0.4887,  0.5240],\n",
      "         [ 0.4208, -0.2635, -0.0619],\n",
      "         [ 0.5133, -0.1343, -0.1466]]])), ('conv1.bias', tensor([-0.3190, -0.0330,  0.0064,  0.1227,  0.2773])), ('conv2.weight', tensor([[[ 0.1485,  0.2653,  0.2102, -0.2603,  0.2093],\n",
      "         [-0.2782, -0.1281,  0.2997,  0.3013,  0.3720],\n",
      "         [-0.3849,  0.0593, -0.3018,  0.0773, -0.1321],\n",
      "         [ 0.2473, -0.1473,  0.1716,  0.0083,  0.1994],\n",
      "         [-0.2193, -0.3334, -0.0741,  0.2403, -0.3519]],\n",
      "\n",
      "        [[-0.0705, -0.0274,  0.3531, -0.3557, -0.0837],\n",
      "         [ 0.1175, -0.2160,  0.1255,  0.1352,  0.2925],\n",
      "         [-0.1661, -0.3442,  0.3568,  0.2394, -0.2708],\n",
      "         [-0.0169,  0.3665,  0.3591,  0.0755,  0.1362],\n",
      "         [ 0.2582,  0.3850,  0.3202, -0.0336, -0.2649]],\n",
      "\n",
      "        [[-0.0114, -0.0111, -0.2380,  0.3589, -0.3400],\n",
      "         [-0.1929, -0.3834, -0.0643,  0.3468,  0.1993],\n",
      "         [-0.3555,  0.2061,  0.1459,  0.3427,  0.1114],\n",
      "         [ 0.3123,  0.2453, -0.0880,  0.2512,  0.0818],\n",
      "         [-0.0269, -0.1930, -0.2992, -0.1518, -0.0044]],\n",
      "\n",
      "        [[ 0.0334, -0.3165,  0.2543, -0.1949,  0.1939],\n",
      "         [ 0.1260,  0.3916,  0.1318, -0.1316,  0.0307],\n",
      "         [ 0.1885, -0.0665,  0.1789,  0.3110, -0.3306],\n",
      "         [-0.2294, -0.3969,  0.3239,  0.2004, -0.1861],\n",
      "         [ 0.1921,  0.0735, -0.2082, -0.0751,  0.0238]],\n",
      "\n",
      "        [[-0.3779,  0.2878, -0.1510, -0.3021,  0.1764],\n",
      "         [ 0.2112,  0.1551,  0.2291, -0.1787, -0.3844],\n",
      "         [ 0.2374, -0.0727,  0.2167, -0.2206,  0.2368],\n",
      "         [ 0.1725, -0.3316, -0.3583,  0.1727,  0.2810],\n",
      "         [ 0.2131, -0.1359, -0.0698, -0.3248,  0.1622]],\n",
      "\n",
      "        [[ 0.1387, -0.2042, -0.1038, -0.0705,  0.2258],\n",
      "         [-0.1995,  0.1887, -0.0695,  0.2974, -0.2863],\n",
      "         [-0.3099,  0.0069, -0.2249, -0.2035, -0.1299],\n",
      "         [ 0.3464,  0.3522,  0.1048,  0.0640,  0.2298],\n",
      "         [-0.2317, -0.2686, -0.0249, -0.3894, -0.0950]],\n",
      "\n",
      "        [[-0.1884,  0.3053, -0.0739, -0.3696, -0.2076],\n",
      "         [ 0.1013, -0.1914,  0.1274,  0.1700,  0.1541],\n",
      "         [ 0.2163,  0.1255,  0.2841, -0.2015,  0.0980],\n",
      "         [-0.2629,  0.1280, -0.1306,  0.1933,  0.3361],\n",
      "         [-0.3936,  0.3915,  0.3693,  0.1128, -0.0067]],\n",
      "\n",
      "        [[ 0.2804,  0.3877, -0.2742, -0.1058, -0.3871],\n",
      "         [-0.1625,  0.3924,  0.2665,  0.0780,  0.0507],\n",
      "         [ 0.1976, -0.3480, -0.3130,  0.1063,  0.0146],\n",
      "         [ 0.1803,  0.1432, -0.2373, -0.1968,  0.2033],\n",
      "         [-0.0397, -0.3280, -0.2851,  0.0957, -0.0485]],\n",
      "\n",
      "        [[-0.2644, -0.2338, -0.0941,  0.1229,  0.0951],\n",
      "         [ 0.0314,  0.3598,  0.2271,  0.3136,  0.3216],\n",
      "         [-0.0737,  0.1196,  0.2500, -0.0389, -0.3116],\n",
      "         [ 0.2396, -0.2635, -0.3093, -0.2515,  0.2158],\n",
      "         [-0.2441,  0.2623, -0.2754,  0.0231,  0.1422]],\n",
      "\n",
      "        [[-0.0908,  0.1228,  0.3264, -0.2303, -0.1861],\n",
      "         [-0.0177,  0.1137,  0.3017, -0.1846,  0.2249],\n",
      "         [ 0.1505,  0.0558,  0.2934,  0.3733,  0.3600],\n",
      "         [ 0.3854,  0.3164, -0.2113,  0.3361, -0.1564],\n",
      "         [ 0.2566,  0.3085, -0.2714,  0.3544, -0.1562]]])), ('conv2.bias', tensor([-0.1552,  0.0062, -0.0365, -0.0198,  0.1161,  0.0489, -0.1151,  0.1912,\n",
      "        -0.0657,  0.0572])), ('conv3.weight', tensor([[[ 0.0456, -0.1261, -0.0255, -0.2443, -0.3256],\n",
      "         [ 0.2710, -0.1356, -0.2887, -0.2180,  0.2077],\n",
      "         [ 0.2721, -0.0082,  0.0921, -0.0319, -0.3083],\n",
      "         [ 0.0087, -0.2995,  0.2699,  0.2902, -0.1455],\n",
      "         [ 0.3146,  0.2041,  0.3057, -0.1433, -0.1584],\n",
      "         [ 0.1711, -0.0137, -0.3010, -0.2381, -0.1100],\n",
      "         [ 0.1552,  0.0606,  0.3204, -0.0120, -0.3184],\n",
      "         [ 0.2873, -0.2069,  0.3354, -0.0610,  0.0969],\n",
      "         [ 0.3418,  0.3473,  0.0084, -0.3173,  0.0667],\n",
      "         [-0.3346,  0.1750, -0.0131,  0.0699,  0.2142]],\n",
      "\n",
      "        [[-0.2631, -0.2282,  0.1242,  0.2883,  0.1718],\n",
      "         [-0.0450,  0.2654,  0.2758, -0.0049, -0.0586],\n",
      "         [-0.2753, -0.2125,  0.3048, -0.1655,  0.1533],\n",
      "         [-0.0148, -0.2866, -0.2762, -0.0518, -0.1407],\n",
      "         [ 0.2895, -0.2332,  0.2559, -0.2206,  0.0229],\n",
      "         [-0.2964,  0.1347, -0.1565, -0.2872, -0.0525],\n",
      "         [ 0.0092,  0.2062, -0.0109, -0.2112, -0.1006],\n",
      "         [-0.2031,  0.3176,  0.2663, -0.0640, -0.0981],\n",
      "         [-0.2051, -0.2489, -0.2089,  0.2169,  0.2972],\n",
      "         [ 0.2773, -0.2274, -0.2277,  0.0085, -0.2351]],\n",
      "\n",
      "        [[-0.1631,  0.0969, -0.2799,  0.1251, -0.0712],\n",
      "         [ 0.2646,  0.0713, -0.0230, -0.2106, -0.2286],\n",
      "         [ 0.2910, -0.1349, -0.3026, -0.1409, -0.2783],\n",
      "         [ 0.3181,  0.1694,  0.0736, -0.0173, -0.0476],\n",
      "         [-0.0187,  0.3045,  0.1209,  0.2174, -0.1154],\n",
      "         [-0.3276, -0.3145, -0.0710, -0.3314, -0.3178],\n",
      "         [-0.0052, -0.1518, -0.2599, -0.0096, -0.0059],\n",
      "         [ 0.1907, -0.1790,  0.0247,  0.1995, -0.0437],\n",
      "         [-0.2948,  0.1539,  0.1236,  0.1430, -0.2488],\n",
      "         [ 0.2461, -0.1687,  0.0475, -0.0494,  0.0675]],\n",
      "\n",
      "        [[ 0.2681, -0.1614, -0.2425,  0.0508, -0.0378],\n",
      "         [-0.2839,  0.0451, -0.2625,  0.1672, -0.0052],\n",
      "         [ 0.2559,  0.2734,  0.0011,  0.0784,  0.2571],\n",
      "         [ 0.0516,  0.1807, -0.1432, -0.0344,  0.1417],\n",
      "         [-0.1484, -0.0587, -0.0791,  0.1891, -0.1402],\n",
      "         [-0.1915,  0.1689, -0.1066,  0.1136,  0.2296],\n",
      "         [-0.1901,  0.0512, -0.2408,  0.1145, -0.2926],\n",
      "         [ 0.3236, -0.0423, -0.3162,  0.3462,  0.2198],\n",
      "         [ 0.0606,  0.0638, -0.3079,  0.2777, -0.3010],\n",
      "         [-0.0518,  0.1400,  0.1027, -0.0381,  0.1630]],\n",
      "\n",
      "        [[ 0.2840,  0.3233, -0.2008, -0.1185,  0.3268],\n",
      "         [ 0.0022, -0.3445,  0.1087,  0.0345,  0.0708],\n",
      "         [ 0.0708,  0.1490, -0.2982, -0.3305, -0.1005],\n",
      "         [ 0.2860,  0.0817,  0.0305,  0.0561,  0.3106],\n",
      "         [ 0.3306,  0.1408, -0.2751,  0.0620,  0.1548],\n",
      "         [ 0.1368,  0.1390, -0.0979, -0.0595,  0.3017],\n",
      "         [-0.0183, -0.0532, -0.0010,  0.2492,  0.2516],\n",
      "         [ 0.1917, -0.1788, -0.3038,  0.0791, -0.1341],\n",
      "         [ 0.1801,  0.0129,  0.2879,  0.1970, -0.0408],\n",
      "         [ 0.1490, -0.1571,  0.0862,  0.0405, -0.2436]],\n",
      "\n",
      "        [[-0.0412,  0.2516,  0.2973,  0.3020, -0.1673],\n",
      "         [ 0.1727,  0.3016,  0.1626, -0.1650,  0.3409],\n",
      "         [-0.2595,  0.1740,  0.1011, -0.2016, -0.3245],\n",
      "         [ 0.0719,  0.1606, -0.2331, -0.1453,  0.0587],\n",
      "         [-0.1377,  0.1411,  0.2836, -0.0479,  0.0676],\n",
      "         [-0.0297,  0.0573,  0.1675,  0.1402, -0.0786],\n",
      "         [-0.0145, -0.1465,  0.0903,  0.2922, -0.0270],\n",
      "         [ 0.2874, -0.1979, -0.3157,  0.1598, -0.2070],\n",
      "         [-0.2018, -0.2569,  0.2354, -0.0317, -0.2265],\n",
      "         [-0.2687,  0.2575,  0.0402, -0.3168,  0.2376]],\n",
      "\n",
      "        [[ 0.3501,  0.1021,  0.2167,  0.2036,  0.1917],\n",
      "         [-0.1330, -0.0100, -0.0818, -0.2936,  0.1698],\n",
      "         [-0.2283,  0.1311, -0.0131,  0.3028, -0.1301],\n",
      "         [-0.2299, -0.1942,  0.1869, -0.2841,  0.1248],\n",
      "         [-0.2032, -0.0185,  0.0225,  0.0958, -0.0394],\n",
      "         [-0.0358, -0.0055,  0.2336, -0.1915, -0.1287],\n",
      "         [ 0.1589,  0.1467,  0.1301,  0.2404, -0.2555],\n",
      "         [-0.1783,  0.1226,  0.0549,  0.2458,  0.0536],\n",
      "         [-0.2969, -0.0304,  0.2903,  0.1534,  0.2001],\n",
      "         [-0.1087,  0.0907,  0.0768, -0.0827, -0.1680]],\n",
      "\n",
      "        [[-0.2394,  0.0713,  0.1556, -0.1379, -0.1705],\n",
      "         [ 0.0738,  0.3302, -0.3310, -0.2893,  0.0928],\n",
      "         [ 0.0388,  0.1606, -0.3056,  0.0942,  0.1224],\n",
      "         [ 0.2549,  0.3363, -0.1240,  0.2660,  0.0530],\n",
      "         [ 0.0747,  0.2200, -0.2778, -0.2904,  0.0621],\n",
      "         [-0.2844, -0.1078, -0.0703, -0.2214,  0.2155],\n",
      "         [ 0.1467, -0.0491,  0.1120, -0.2001,  0.3214],\n",
      "         [ 0.3465,  0.3350,  0.1557,  0.0508,  0.2411],\n",
      "         [-0.3211,  0.3127,  0.0370, -0.1930, -0.2684],\n",
      "         [ 0.0559, -0.3218,  0.2366,  0.0309, -0.3061]],\n",
      "\n",
      "        [[-0.0478, -0.2826, -0.2499,  0.2062, -0.2354],\n",
      "         [ 0.0233,  0.1464, -0.0020, -0.3363,  0.1513],\n",
      "         [ 0.0642,  0.0435,  0.2326,  0.2283, -0.3270],\n",
      "         [-0.2721, -0.1347,  0.3244, -0.3139,  0.0531],\n",
      "         [ 0.1855, -0.2404,  0.3295, -0.1964, -0.1447],\n",
      "         [ 0.1021, -0.1086,  0.2907, -0.2546,  0.2582],\n",
      "         [ 0.1083, -0.1532,  0.2361,  0.1270, -0.1087],\n",
      "         [-0.1193, -0.2948, -0.0959,  0.1259,  0.2371],\n",
      "         [ 0.3422, -0.1254, -0.2071,  0.0716, -0.1135],\n",
      "         [ 0.1264,  0.2159,  0.1451, -0.0878, -0.2500]],\n",
      "\n",
      "        [[ 0.3305, -0.0089, -0.0439, -0.3118, -0.1538],\n",
      "         [-0.1043,  0.0584,  0.0519,  0.2330,  0.0944],\n",
      "         [-0.0491, -0.0414,  0.2235, -0.3363, -0.2720],\n",
      "         [ 0.1145,  0.0760,  0.0460, -0.3158, -0.0459],\n",
      "         [ 0.3293, -0.3166, -0.1181, -0.0233,  0.1921],\n",
      "         [ 0.2415,  0.2877, -0.0626,  0.2721,  0.2691],\n",
      "         [-0.0375, -0.0598,  0.1412, -0.2289,  0.1405],\n",
      "         [-0.1564, -0.3082, -0.2199,  0.0120, -0.0394],\n",
      "         [ 0.0590,  0.2970,  0.3266,  0.2541,  0.2615],\n",
      "         [-0.1382,  0.1679,  0.1207,  0.0095,  0.2756]]])), ('conv3.bias', tensor([ 0.1222,  0.0462, -0.1020, -0.0936,  0.0917, -0.1353,  0.0526,  0.0227,\n",
      "        -0.0144, -0.0580])), ('fc.weight', tensor([[ 0.0151,  0.0244,  0.0261,  ..., -0.0219,  0.0191,  0.0111],\n",
      "        [-0.0152, -0.0262,  0.0245,  ..., -0.0048,  0.0184,  0.0063],\n",
      "        [-0.0424, -0.0178, -0.0415,  ...,  0.0164, -0.0102, -0.0025],\n",
      "        [ 0.0075, -0.0299, -0.0084,  ..., -0.0158, -0.0386, -0.0064],\n",
      "        [ 0.0139, -0.0072, -0.0205,  ..., -0.0234,  0.0308, -0.0054],\n",
      "        [-0.0162,  0.0207,  0.0372,  ...,  0.0130,  0.0244,  0.0047]])), ('fc.bias', tensor([-0.0127,  0.0194,  0.0296, -0.0316, -0.0196,  0.0083]))])\n"
     ]
    }
   ],
   "source": [
    "Net = ConvNet().eval()\n",
    "Net.load_state_dict(torch.load('model_dropout5.pt'))\n",
    "print(Net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv1d(3, 5, kernel_size=(3,), stride=(1,))\n",
       "  (conv2): Conv1d(5, 10, kernel_size=(5,), stride=(1,))\n",
       "  (conv3): Conv1d(10, 10, kernel_size=(5,), stride=(1,))\n",
       "  (conv4): Conv1d(10, 10, kernel_size=(3,), stride=(1,))\n",
       "  (conv5): Conv1d(10, 10, kernel_size=(3,), stride=(1,))\n",
       "  (fc): Linear(in_features=660, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_accuracy(dataloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "#         print(images)\n",
    "        outputs = Net(images)\n",
    "#         print('Output : ')\n",
    "#         print(outputs)\n",
    "        \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "#         print('Label : ')\n",
    "#         print(label_ind)\n",
    "#         print('Prediction : ')\n",
    "#         print(pred_ind)\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "#         print('correct - ', correct, ' of ', total, 'as of now')\n",
    "#         print('image - ', total, ' of ', len(dataloader.dataset) // 80)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net.cpu()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6937281558388158\n",
      "0.7080129253926701\n",
      "0.6911097022251309\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader))\n",
    "print(_get_accuracy(valloader))\n",
    "print(_get_accuracy(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
