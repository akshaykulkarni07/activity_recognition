{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from torch.autograd import Variable\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('data_preparation/train.csv', header = 0, index_col = 0)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('data_preparation/test.csv', header = 0, index_col = 0)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('data_preparation/val.csv', header = 0, index_col = 0)\n",
    "        self.transform = transform\n",
    "        self.df = self.df.reset_index()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df.iloc[idx : idx + 80, 3 : ].values\n",
    "        ind = np.argmax(np.sum(y, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + 80, : 3].values\n",
    "        x = x.astype('float')\n",
    "        assert(x.shape == (80, 3))\n",
    "        assert(label.shape == (6, ))\n",
    "        return x, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "def my_collate(batch):\n",
    "    \"Puts each data field into a tensor with outer dimension batch size\"\n",
    "    batch = list(filter(lambda x : x is not None, batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "train_indices = [(i * 80) for i in range(len(trainset) // 80)]\n",
    "val_indices = [(i * 80) for i in range(len(valset) // 80)]\n",
    "test_indices = [(i * 80) for i in range(len(testset) // 80)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = batch_size, sampler = SubsetRandomSampler(train_indices), collate_fn = my_collate, drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), collate_fn = my_collate, drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), collate_fn = my_collate, drop_last = True)\n",
    "\n",
    "# for idx, (x, y) in enumerate(trainloader) :\n",
    "#     print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self, code_size):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        self.code_size = code_size\n",
    "        # defining layers\n",
    "        # input size - batch_size x 3 x 100\n",
    "        conv1 = nn.Conv1d(3, 10, 3)\n",
    "        # after conv1 - batch_size x 10 x 98\n",
    "        conv2 = nn.Conv1d(10, 20, 1)\n",
    "        # after conv2 - batch_size x 10 x 98\n",
    "        enc_fc = nn.Linear(10 * 98, self.code_size)\n",
    "        dec_fc = nn.Linear(self.code_size, 10 * 98)\n",
    "        deconv2 = nn.ConvTranspose1d(20, 10, 1)\n",
    "        deconv1 = nn.ConvTranspose1d(10, 3, 3)\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        code = self.encode(signal)\n",
    "        out = self.decode(code)\n",
    "        return out, code\n",
    "    \n",
    "    def encode(signal):\n",
    "        signal = signal.view(16, 3, 80)\n",
    "        code = F.sigmoid(self.conv1(signal))\n",
    "        code = F.sigmoid(self.conv2(code))\n",
    "        code = F.sigmoid(self.enc_fc(code))\n",
    "        return code\n",
    "    \n",
    "    def decode(code):\n",
    "        out = F.sigmoid(self.dec_fc(code))\n",
    "        out = F.sigmoid(self.deconv2(out))\n",
    "        out = F.sigmoid(self.deconv1(out))\n",
    "        return out\n",
    "    \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 10, 5)\n",
    "        self.conv3 = nn.Conv1d(10, 10, 5)\n",
    "        self.fc = nn.Linear(70 * 10, 6)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal = signal.view(batch_size, 3, 80)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(-1, 70 * 10)\n",
    "        out = self.fc(out)\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "    \n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.0\n",
      "74.0\n",
      "70.0\n"
     ]
    }
   ],
   "source": [
    "def output_size(n, f, p = 0, s = 1):\n",
    "    return (((n + 2 * p - f) / s) + 1)\n",
    "\n",
    "print(output_size(80, 3))\n",
    "print(output_size(78, 5))\n",
    "print(output_size(74, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(Net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "total_step = len(trainset) // 80\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = Variable(images).cuda().float()\n",
    "        labels = Variable(labels).cuda()\n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "\n",
    "        loss = F.cross_entropy(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         clear_output(wait=True)\n",
    "#         print(f'epoch: {epoch}, step : {i * len(images)} of {total_step}, loss : {loss}')\n",
    "#         if i % 10 == 0 :\n",
    "#             print('epoch = ', epoch, ' step = ', i * len(images), ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    val = []\n",
    "    for i, (images, labels) in enumerate(valloader):\n",
    "        images = Variable(images).cuda().float()\n",
    "        labels = Variable(labels).cuda()\n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = Net(images)\n",
    "#         loss = criterion(outputs.float(), labels.float())\n",
    "        loss = F.cross_entropy(outputs, target)\n",
    "        val.append(loss)\n",
    "#     print(f'validation loss : {sum(val)/len(val)}')\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net, 'model_dropout.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = torch.load('model_dropout.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct -  29  of  256 as of now\n",
      "image -  256  of  783360\n",
      "correct -  52  of  512 as of now\n",
      "image -  512  of  783360\n",
      "correct -  75  of  768 as of now\n",
      "image -  768  of  783360\n",
      "correct -  106  of  1024 as of now\n",
      "image -  1024  of  783360\n",
      "correct -  126  of  1280 as of now\n",
      "image -  1280  of  783360\n",
      "correct -  146  of  1536 as of now\n",
      "image -  1536  of  783360\n",
      "correct -  170  of  1792 as of now\n",
      "image -  1792  of  783360\n",
      "correct -  190  of  2048 as of now\n",
      "image -  2048  of  783360\n",
      "correct -  216  of  2304 as of now\n",
      "image -  2304  of  783360\n",
      "correct -  242  of  2560 as of now\n",
      "image -  2560  of  783360\n",
      "correct -  264  of  2816 as of now\n",
      "image -  2816  of  783360\n",
      "correct -  292  of  3072 as of now\n",
      "image -  3072  of  783360\n",
      "correct -  320  of  3328 as of now\n",
      "image -  3328  of  783360\n",
      "correct -  343  of  3584 as of now\n",
      "image -  3584  of  783360\n",
      "correct -  369  of  3840 as of now\n",
      "image -  3840  of  783360\n",
      "correct -  393  of  4096 as of now\n",
      "image -  4096  of  783360\n",
      "correct -  423  of  4352 as of now\n",
      "image -  4352  of  783360\n",
      "correct -  460  of  4608 as of now\n",
      "image -  4608  of  783360\n",
      "correct -  490  of  4864 as of now\n",
      "image -  4864  of  783360\n",
      "correct -  516  of  5120 as of now\n",
      "image -  5120  of  783360\n",
      "correct -  537  of  5376 as of now\n",
      "image -  5376  of  783360\n",
      "correct -  566  of  5632 as of now\n",
      "image -  5632  of  783360\n",
      "correct -  587  of  5888 as of now\n",
      "image -  5888  of  783360\n",
      "correct -  610  of  6144 as of now\n",
      "image -  6144  of  783360\n",
      "correct -  631  of  6400 as of now\n",
      "image -  6400  of  783360\n",
      "correct -  663  of  6656 as of now\n",
      "image -  6656  of  783360\n",
      "correct -  688  of  6912 as of now\n",
      "image -  6912  of  783360\n",
      "correct -  715  of  7168 as of now\n",
      "image -  7168  of  783360\n",
      "correct -  735  of  7424 as of now\n",
      "image -  7424  of  783360\n",
      "correct -  767  of  7680 as of now\n",
      "image -  7680  of  783360\n",
      "correct -  790  of  7936 as of now\n",
      "image -  7936  of  783360\n",
      "correct -  819  of  8192 as of now\n",
      "image -  8192  of  783360\n",
      "correct -  850  of  8448 as of now\n",
      "image -  8448  of  783360\n",
      "correct -  879  of  8704 as of now\n",
      "image -  8704  of  783360\n",
      "correct -  906  of  8960 as of now\n",
      "image -  8960  of  783360\n",
      "correct -  921  of  9216 as of now\n",
      "image -  9216  of  783360\n",
      "correct -  948  of  9472 as of now\n",
      "image -  9472  of  783360\n",
      "correct -  966  of  9728 as of now\n",
      "image -  9728  of  783360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09930098684210527"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_accuracy(dataloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "        outputs = Net(images)\n",
    "\n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "\n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "\n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "        print('correct - ', correct, ' of ', total, 'as of now')\n",
    "        print('image - ', total, ' of ', len(dataloader.dataset) // 80)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu()\n",
    "_get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
